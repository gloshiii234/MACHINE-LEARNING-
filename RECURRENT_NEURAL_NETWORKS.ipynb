{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RECCURENT NEURAL NETWORKS(RNN)\n",
    "\n",
    "-Ever wondered how Google's autocomplete feature predicts the rest of the words a user is typing?\n",
    "\n",
    "-it involves a collection of large volumes of most frequently occuring consecutive words and feeding them to a reuccurent neural network  which analyses the data by finding the sequence of words occuring frequently and builds a model to predict the next word in the sentence."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##RECAP ON POPULAR NEURAL NETWORKS\n",
    "\n",
    "1.Feed forward NN-usd in general regression and classification problems\n",
    "2.Convolutional NN- used for image recognition\n",
    "3.Deep NN- used for acoustic modeling\n",
    "4.Deep Belief Network -used for cancer detection\n",
    "5.Reccurent NN- used for speech recognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Issues with feed forward NN\n",
    "\n",
    "1.It cannot handle sequential data\n",
    "2.It considers only the current input\n",
    "3.It cannot memorize previous inputs\n",
    "\n",
    "##WHY RECCURENT NN\n",
    "1.It can handle sequential data\n",
    "2.It considers the current input and also the previously received inputs\n",
    "3.It can memorize previous inputs due to its internal memory\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##OTHER APPLICATIONS OF RECCURENT NN\n",
    "\n",
    "1.Imaging captioning\n",
    "2.Time series prediction(prediction of the prices of stocks in a particular month)\n",
    "3.Natural language processing(Text mining and sentimental analysis)\n",
    "4.Machine Translation(Given an input in one language, translates to different languages)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Types of Reccurent NN\n",
    "\n",
    "1.Single output\n",
    "2.many to one\n",
    "3.multiple outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LONG SHORT TERM MEMORY NETWORKS\n",
    "\n",
    "-LSTMs are special kind of RNNs capable of learning long-term dependencies. They remember information for long periods of time(this is their behaviour)\n",
    "-They have a chain like structure, but the repeating module has a different structure and instead of having a single neural network layer, there are four interacting layers communicating in a very special way.\n",
    "-\n",
    "##3 STEPS IN LSTMNs\n",
    "\n",
    "1.Forget irrelevant parts of previous state(Decides how much of the data it should remember)\n",
    "2.Selectively update cell state values(Decides how much should the unit add to the current state)\n",
    "\n",
    "eg. John called me over the phone yesterday over the phone and he told me he served as a captain for his team.... the important information here is that John served as a captain , the other information can be dropped out.\n",
    "\n",
    "3.Decides what part of the current cell sate make it to the output\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
